---
title: Latest 15 Papers - May 20, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Embodied AI
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[RefDrone: A Challenging Benchmark for Referring Expression Comprehension in Drone Scenes](http://arxiv.org/abs/2502.00392v2)** | 2025-05-19 |  |
| **[PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI](http://arxiv.org/abs/2505.12707v1)** | 2025-05-19 | 9 pages, 8 figures |
| **[EWMBench: Evaluating Scene, Motion, and Semantic Quality in Embodied World Models](http://arxiv.org/abs/2505.09694v2)** | 2025-05-18 | <details><summary>Websi...</summary><p>Website: https://github.com/AgibotTech/EWMBench</p></details> |
| **[Visuospatial Cognitive Assistant](http://arxiv.org/abs/2505.12312v1)** | 2025-05-18 | <details><summary>31 pa...</summary><p>31 pages, 10 figures, 6 tables. The implementation and fine-tuned model (ViCA-7B) are publicly available at https://huggingface.co/nkkbr/ViCA. The ViCA-322K dataset can be found at https://huggingface.co/datasets/nkkbr/ViCA-322K, and the ViCA-Thinking-2.68K dataset is at https://huggingface.co/datasets/nkkbr/ViCA-thinking-2.68k</p></details> |
| **[Emergent Active Perception and Dexterity of Simulated Humanoids from Visual Reinforcement Learning](http://arxiv.org/abs/2505.12278v1)** | 2025-05-18 | <details><summary>Proje...</summary><p>Project page: https://zhengyiluo.github.io/PDC</p></details> |
| **[Latent Action Learning Requires Supervision in the Presence of Distractors](http://arxiv.org/abs/2502.00379v3)** | 2025-05-17 | <details><summary>ICML ...</summary><p>ICML 2025, Poster, Source code: https://github.com/dunnolab/laom</p></details> |
| **[Are Multimodal Large Language Models Ready for Omnidirectional Spatial Reasoning?](http://arxiv.org/abs/2505.11907v1)** | 2025-05-17 |  |
| **[Multi-Modal Multi-Task (M3T) Federated Foundation Models for Embodied AI: Potentials and Challenges for Edge Integration](http://arxiv.org/abs/2505.11191v1)** | 2025-05-16 | <details><summary>10 pa...</summary><p>10 pages, 3 figures, 3 tables</p></details> |
| **[Embodied AI in Machine Learning -- is it Really Embodied?](http://arxiv.org/abs/2505.10705v1)** | 2025-05-15 | 16 pages, 3 figures |
| **[KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems](http://arxiv.org/abs/2505.10183v1)** | 2025-05-15 | <details><summary>9 pag...</summary><p>9 pages, 4 figures. Jieke Lin and Wanyu Wang contributed equally to this work</p></details> |
| **[EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation](http://arxiv.org/abs/2505.10105v1)** | 2025-05-15 |  |
| **[ON as ALC: Active Loop Closing Object Goal Navigation](http://arxiv.org/abs/2412.11523v2)** | 2025-05-14 | <details><summary>Draft...</summary><p>Draft version of a conference paper with 7 pages, 5 figures, and 1 table</p></details> |
| **[Neural Brain: A Neuroscience-inspired Framework for Embodied Agents](http://arxiv.org/abs/2505.07634v2)** | 2025-05-14 | <details><summary>51 pa...</summary><p>51 pages, 17 figures, 9 tables</p></details> |
| **[Generative AI for Autonomous Driving: Frontiers and Opportunities](http://arxiv.org/abs/2505.08854v1)** | 2025-05-13 |  |
| **[LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation](http://arxiv.org/abs/2505.11528v1)** | 2025-05-13 |  |

## Reinforcement Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards](http://arxiv.org/abs/2505.13445v1)** | 2025-05-19 | <details><summary>code ...</summary><p>code available at https://github.com/xyliu-cs/RISE</p></details> |
| **[Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning](http://arxiv.org/abs/2503.15558v3)** | 2025-05-19 |  |
| **[Optimizing Anytime Reasoning via Budget Relative Policy Optimization](http://arxiv.org/abs/2505.13438v1)** | 2025-05-19 |  |
| **[G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning](http://arxiv.org/abs/2505.13426v1)** | 2025-05-19 | <details><summary>21 pa...</summary><p>21 pages, 14 figures, code released at https://github.com/chenllliang/G1</p></details> |
| **[A Dataless Reinforcement Learning Approach to Rounding Hyperplane Optimization for Max-Cut](http://arxiv.org/abs/2505.13405v1)** | 2025-05-19 |  |
| **[Thinkless: LLM Learns When to Think](http://arxiv.org/abs/2505.13379v1)** | 2025-05-19 |  |
| **[Exploiting Symbolic Heuristics for the Synthesis of Domain-Specific Temporal Planning Guidance using Reinforcement Learning](http://arxiv.org/abs/2505.13372v1)** | 2025-05-19 |  |
| **[Certifying Stability of Reinforcement Learning Policies using Generalized Lyapunov Functions](http://arxiv.org/abs/2505.10947v2)** | 2025-05-19 |  |
| **[Yes, Q-learning Helps Offline In-Context RL](http://arxiv.org/abs/2502.17666v3)** | 2025-05-19 |  |
| **[Mixed-Precision Conjugate Gradient Solvers with RL-Driven Precision Tuning](http://arxiv.org/abs/2504.14268v3)** | 2025-05-19 |  |
| **[J4R: Learning to Judge with Equivalent Initial State Group Relative Preference Optimization](http://arxiv.org/abs/2505.13346v1)** | 2025-05-19 | <details><summary>25 pa...</summary><p>25 pages, 4 figures, 6 tables. To be updated with links for code/benchmark</p></details> |
| **[Neural-Enhanced Rate Adaptation and Computation Distribution for Emerging mmWave Multi-User 3D Video Streaming Systems](http://arxiv.org/abs/2505.13337v1)** | 2025-05-19 | <details><summary>Accep...</summary><p>Accepted to be published in IEEE Transaction on Multimedia</p></details> |
| **[CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning](http://arxiv.org/abs/2505.13271v1)** | 2025-05-19 | 11 pages, 5 figures |
| **[Unlocking the Potential of Difficulty Prior in RL-based Multimodal Reasoning](http://arxiv.org/abs/2505.13261v1)** | 2025-05-19 |  |
| **[Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability](http://arxiv.org/abs/2505.13258v1)** | 2025-05-19 |  |

## Robotics
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots](http://arxiv.org/abs/2505.13376v1)** | 2025-05-19 |  |
| **[OPA-Pack: Object-Property-Aware Robotic Bin Packing](http://arxiv.org/abs/2505.13339v1)** | 2025-05-19 | <details><summary>Submi...</summary><p>Submitted to IEEE Transactions on Robotics (TRO) on Feb. 10, 2025</p></details> |
| **[Policy Contrastive Decoding for Robotic Foundation Models](http://arxiv.org/abs/2505.13255v1)** | 2025-05-19 |  |
| **[Interpretable Robotic Friction Learning via Symbolic Regression](http://arxiv.org/abs/2505.13186v1)** | 2025-05-19 |  |
| **[Constraint-Aware Diffusion Guidance for Robotics: Real-Time Obstacle Avoidance for Autonomous Racing](http://arxiv.org/abs/2505.13131v1)** | 2025-05-19 |  |
| **[FACET: Force-Adaptive Control via Impedance Reference Tracking for Legged Robots](http://arxiv.org/abs/2505.06883v2)** | 2025-05-19 |  |
| **[Efficient Multi-robot Active SLAM](http://arxiv.org/abs/2310.06160v2)** | 2025-05-19 | 31 pages, 15 figures |
| **[Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation](http://arxiv.org/abs/2505.12744v1)** | 2025-05-19 | 17 pages, 16 figures |
| **[DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories](http://arxiv.org/abs/2505.12705v1)** | 2025-05-19 | <details><summary>See w...</summary><p>See website for videos: https://research.nvidia.com/labs/gear/dreamgen</p></details> |
| **[The Robot of Theseus: A modular robotic testbed for legged locomotion](http://arxiv.org/abs/2505.12649v1)** | 2025-05-19 |  |
| **[EndoForce: Development of an Intuitive Axial Force Measurement Device for Endoscopic Robotic Systems](http://arxiv.org/abs/2505.12624v1)** | 2025-05-19 |  |
| **[A Comprehensive Survey on Physical Risk Control in the Era of Foundation Model-enabled Robotics](http://arxiv.org/abs/2505.12583v1)** | 2025-05-19 | <details><summary>Accep...</summary><p>Accepted to IJCAI 2025 Survey Track</p></details> |
| **[Development of a non-wearable support robot capable of reproducing natural standing-up movements](http://arxiv.org/abs/2505.12525v1)** | 2025-05-18 |  |
| **[IR2: Implicit Rendezvous for Robotic Exploration Teams under Sparse Intermittent Connectivity](http://arxiv.org/abs/2409.04730v2)** | 2025-05-18 | <details><summary>\c{op...</summary><p>\c{opyright} 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[Shape-Space Deformer: Unified Visuo-Tactile Representations for Robotic Manipulation of Deformable Objects](http://arxiv.org/abs/2409.12419v3)** | 2025-05-18 | Accepted in ICRA2025 |

