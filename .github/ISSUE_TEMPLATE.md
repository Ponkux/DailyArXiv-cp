---
title: Latest 15 Papers - December 05, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Embodied AI
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer](https://arxiv.org/abs/2512.05060v1)** | 2025-12-04 | <details><summary>Code:...</summary><p>Code: https://github.com/hustvl/4DLangVGGT, Webpage: https://hustvl.github.io/4DLangVGGT</p></details> |
| **[LLMscape](https://arxiv.org/abs/2511.07161v2)** | 2025-12-04 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025, Creative AI Track (updated to include poster)</p></details> |
| **[Towards Cross-View Point Correspondence in Vision-Language Models](https://arxiv.org/abs/2512.04686v1)** | 2025-12-04 |  |
| **[ViRectify: A Challenging Benchmark for Video Reasoning Correction with Multimodal Large Language Models](https://arxiv.org/abs/2512.01424v3)** | 2025-12-04 | 22 pages, 11 figures |
| **[X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale](https://arxiv.org/abs/2512.04537v1)** | 2025-12-04 |  |
| **[EgoLCD: Egocentric Video Generation with Long Context Diffusion](https://arxiv.org/abs/2512.04515v1)** | 2025-12-04 |  |
| **[ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models](https://arxiv.org/abs/2512.04308v1)** | 2025-12-03 | <details><summary>https...</summary><p>https://sites.google.com/view/responsible-robotbench</p></details> |
| **[TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image](https://arxiv.org/abs/2512.01204v2)** | 2025-12-03 | <details><summary>Proje...</summary><p>Project page: https://d-robotics-ai-lab.github.io/TabletopGen.project/</p></details> |
| **[Multimodal Reinforcement Learning with Agentic Verifier for AI Agents](https://arxiv.org/abs/2512.03438v1)** | 2025-12-03 |  |
| **[YOLOA: Real-Time Affordance Detection via LLM Adapter](https://arxiv.org/abs/2512.03418v1)** | 2025-12-03 | <details><summary>13 pa...</summary><p>13 pages, 9 figures, conference</p></details> |
| **[U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences](https://arxiv.org/abs/2512.02982v1)** | 2025-12-02 | <details><summary>Prepr...</summary><p>Preprint; 19 pages, 7 figures, 8 tables</p></details> |
| **[AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention](https://arxiv.org/abs/2511.18960v2)** | 2025-12-02 | 18 pages, 10 figures |
| **[Reframing Human-Robot Interaction Through Extended Reality: Unlocking Safer, Smarter, and More Empathic Interactions with Virtual Robots and Foundation Models](https://arxiv.org/abs/2512.02569v1)** | 2025-12-02 | <details><summary>This ...</summary><p>This paper is under review</p></details> |
| **[SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge](https://arxiv.org/abs/2512.01629v2)** | 2025-12-02 | <details><summary>Proje...</summary><p>Project page: https://heyumeng.com/SPARK/index.html. 17 pages, 7 figures</p></details> |
| **[Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration](https://arxiv.org/abs/2512.02458v1)** | 2025-12-02 |  |

## Reinforcement Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning](https://arxiv.org/abs/2512.05111v1)** | 2025-12-04 |  |
| **[STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models](https://arxiv.org/abs/2512.05107v1)** | 2025-12-04 |  |
| **[Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning](https://arxiv.org/abs/2512.05105v1)** | 2025-12-04 |  |
| **[Structured Document Translation via Format Reinforcement Learning](https://arxiv.org/abs/2512.05100v1)** | 2025-12-04 | <details><summary>IJCNL...</summary><p>IJCNLP-AACL 2025 Main (Oral)</p></details> |
| **[SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards](https://arxiv.org/abs/2512.05098v1)** | 2025-12-04 |  |
| **[From Generated Human Videos to Physically Plausible Robot Trajectories](https://arxiv.org/abs/2512.05094v1)** | 2025-12-04 | <details><summary>For p...</summary><p>For project website, see https://genmimic.github.io</p></details> |
| **[Path Channels and Plan Extension Kernels: a Mechanistic Description of Planning in a Sokoban RNN](https://arxiv.org/abs/2506.10138v2)** | 2025-12-04 | <details><summary>Prese...</summary><p>Presented at the Mechanistic Interpretability Workshop at NeurIPS 2025. 34 pages, 26 figures</p></details> |
| **[Experience Replay with Random Reshuffling](https://arxiv.org/abs/2503.02269v2)** | 2025-12-04 |  |
| **[The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439v2)** | 2025-12-04 |  |
| **[Realizable Abstractions: Near-Optimal Hierarchical Reinforcement Learning](https://arxiv.org/abs/2512.04958v1)** | 2025-12-04 |  |
| **[CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent](https://arxiv.org/abs/2512.04949v1)** | 2025-12-04 | 10 pages, 4 figures |
| **[Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty](https://arxiv.org/abs/2512.04918v1)** | 2025-12-04 |  |
| **[OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943v2)** | 2025-12-04 | <details><summary>Sourc...</summary><p>Source code and data available at: https://github.com/marytonwe/OPTIC-ER.git</p></details> |
| **[What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking](https://arxiv.org/abs/2509.04791v2)** | 2025-12-04 |  |
| **[HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments](https://arxiv.org/abs/2511.20275v3)** | 2025-12-04 |  |

## Robotics
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Generated Human Videos to Physically Plausible Robot Trajectories](https://arxiv.org/abs/2512.05094v1)** | 2025-12-04 | <details><summary>For p...</summary><p>For project website, see https://genmimic.github.io</p></details> |
| **[Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain](https://arxiv.org/abs/2512.05008v1)** | 2025-12-04 |  |
| **[The Autonomy-Alignment Problem in Open-Ended Learning Robots: Formalising the Purpose Framework](https://arxiv.org/abs/2403.02514v3)** | 2025-12-04 | 33 pages, 5 figures |
| **[HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments](https://arxiv.org/abs/2511.20275v3)** | 2025-12-04 |  |
| **[MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation](https://arxiv.org/abs/2512.04813v1)** | 2025-12-04 | 9 pages, 9 figures |
| **[PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement Learning for Legged Robots in Crawl Spaces](https://arxiv.org/abs/2508.09950v2)** | 2025-12-04 | Accepted by RA-L |
| **[X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale](https://arxiv.org/abs/2512.04537v1)** | 2025-12-04 |  |
| **[One Ring to Rule Them All: Constrained Distributional Control for Massive-Scale Heterogeneous Robotic Ensemble Systems](https://arxiv.org/abs/2512.04502v1)** | 2025-12-04 | 9 pages, 8 figures |
| **[MARL Warehouse Robots](https://arxiv.org/abs/2512.04463v1)** | 2025-12-04 | <details><summary>6 pag...</summary><p>6 pages, 4 tables. Project documentation: https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/</p></details> |
| **[Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration](https://arxiv.org/abs/2512.04453v1)** | 2025-12-04 | <details><summary>Accep...</summary><p>Accepted to ACM/IEEE International Conference on Human-Robot Interaction, 2026 (HRI 2026), 10 pages, 4 figures</p></details> |
| **[Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops](https://arxiv.org/abs/2512.04446v1)** | 2025-12-04 |  |
| **[RoboBPP: Benchmarking Robotic Online Bin Packing with Physics-based Simulation](https://arxiv.org/abs/2512.04415v1)** | 2025-12-04 | <details><summary>Under...</summary><p>Under review at the International Journal of Robotics Research (IJRR)</p></details> |
| **[Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation](https://arxiv.org/abs/2512.04404v1)** | 2025-12-04 | <details><summary>34 pa...</summary><p>34 pages, is submitted RAS Journal</p></details> |
| **[Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning](https://arxiv.org/abs/2512.00074v2)** | 2025-12-04 |  |
| **[Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration](https://arxiv.org/abs/2510.05013v4)** | 2025-12-04 | <details><summary>20 pa...</summary><p>20 pages, 19 pages of supplementary material</p></details> |

