---
title: Latest 15 Papers - June 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Embodied AI
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Object-Centric Latent Action Learning](http://arxiv.org/abs/2502.09680v2)** | 2025-06-12 | <details><summary>Accep...</summary><p>Accepted by Workshop on World Models at ICLR 2025</p></details> |
| **[Latent Action Learning Requires Supervision in the Presence of Distractors](http://arxiv.org/abs/2502.00379v5)** | 2025-06-12 | <details><summary>ICML ...</summary><p>ICML 2025, Poster, Project Page: https://laom.dunnolab.ai/, Source code: https://github.com/dunnolab/laom</p></details> |
| **[EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence](http://arxiv.org/abs/2506.10600v1)** | 2025-06-12 |  |
| **[A Navigation Framework Utilizing Vision-Language Models](http://arxiv.org/abs/2506.10172v1)** | 2025-06-11 |  |
| **[OctoNav: Towards Generalist Embodied Navigation](http://arxiv.org/abs/2506.09839v1)** | 2025-06-11 | 31 pages, 25 figures |
| **[Analytic Task Scheduler: Recursive Least Squares Based Method for Continual Learning in Embodied Foundation Models](http://arxiv.org/abs/2506.09623v1)** | 2025-06-11 |  |
| **[What Can RL Bring to VLA Generalization? An Empirical Study](http://arxiv.org/abs/2505.19789v2)** | 2025-06-11 |  |
| **[VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning](http://arxiv.org/abs/2506.09049v1)** | 2025-06-10 | <details><summary>Proje...</summary><p>Project page: https://faceong.github.io/VIKI-R/</p></details> |
| **[Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos](http://arxiv.org/abs/2506.08334v1)** | 2025-06-10 | <details><summary>Proje...</summary><p>Project website can be found at https://3dlg-hcvc.github.io/video2articulation/</p></details> |
| **[Dreamland: Controllable World Creation with Simulator and Generative Models](http://arxiv.org/abs/2506.08006v1)** | 2025-06-09 | <details><summary>Proje...</summary><p>Project Page: https://metadriverse.github.io/dreamland/</p></details> |
| **[DINeMo: Learning Neural Mesh Models with no 3D Annotations](http://arxiv.org/abs/2503.20220v2)** | 2025-06-09 | <details><summary>Accep...</summary><p>Accepted to 3rd Workshop on Compositional 3D Vision at CVPR 2025 (C3DV)</p></details> |
| **[LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization](http://arxiv.org/abs/2506.07570v1)** | 2025-06-09 |  |
| **[Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI](http://arxiv.org/abs/2506.07286v1)** | 2025-06-08 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025 Embodied AI Workshop</p></details> |
| **[DaDu-Corki: Algorithm-Architecture Co-Design for Embodied AI-powered Robotic Manipulation](http://arxiv.org/abs/2407.04292v5)** | 2025-06-08 |  |
| **[Hallucinate, Ground, Repeat: A Framework for Generalized Visual Relationship Detection](http://arxiv.org/abs/2506.05651v1)** | 2025-06-06 | <details><summary>22 pa...</summary><p>22 pages, 9 figures, 5 tables</p></details> |

## Reinforcement Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop](http://arxiv.org/abs/2506.10968v1)** | 2025-06-12 | <details><summary>Proje...</summary><p>Project page: https://www.eyerobot.net/</p></details> |
| **[AssistanceZero: Scalably Solving Assistance Games](http://arxiv.org/abs/2504.07091v2)** | 2025-06-12 | <details><summary>Prese...</summary><p>Presented at ICML 2025</p></details> |
| **[Spurious Rewards: Rethinking Training Signals in RLVR](http://arxiv.org/abs/2506.10947v1)** | 2025-06-12 |  |
| **[Self-Adapting Language Models](http://arxiv.org/abs/2506.10943v1)** | 2025-06-12 |  |
| **[Passivity-Centric Safe Reinforcement Learning for Contact-Rich Robotic Tasks](http://arxiv.org/abs/2503.00287v2)** | 2025-06-12 | revision version |
| **[Magistral](http://arxiv.org/abs/2506.10910v1)** | 2025-06-12 |  |
| **[Adaptive Job Scheduling in Quantum Clouds Using Reinforcement Learning](http://arxiv.org/abs/2506.10889v1)** | 2025-06-12 | <details><summary>10 pa...</summary><p>10 pages, 6 figures, ICPP 2025</p></details> |
| **[Sailing by the Stars: A Survey on Reward Models and Learning Strategies for Learning from Rewards](http://arxiv.org/abs/2505.02686v2)** | 2025-06-12 | 36 Pages |
| **[Q-Ponder: A Unified Training Pipeline for Reasoning-based Visual Quality Assessment](http://arxiv.org/abs/2506.05384v2)** | 2025-06-12 |  |
| **[Viability of Future Actions: Robust Safety in Reinforcement Learning via Entropy Regularization](http://arxiv.org/abs/2506.10871v1)** | 2025-06-12 | <details><summary>24 pa...</summary><p>24 pages, 11 figures, 2 tables. Accepted for publication at ECML-PKDD 2025</p></details> |
| **[Joint Beamforming with Extremely Large Scale RIS: A Sequential Multi-Agent A2C Approach](http://arxiv.org/abs/2506.10815v1)** | 2025-06-12 |  |
| **[Human-Robot Navigation using Event-based Cameras and Reinforcement Learning](http://arxiv.org/abs/2506.10790v1)** | 2025-06-12 | <details><summary>https...</summary><p>https://ibugueno.github.io/hr-navigation-using-event-cameras-and-rl/</p></details> |
| **[Divide-Fuse-Conquer: Eliciting "Aha Moments" in Multi-Scenario Games](http://arxiv.org/abs/2505.16401v4)** | 2025-06-12 | <details><summary>25 pa...</summary><p>25 pages, 13 figures, and 8 tables</p></details> |
| **[Mimicking Human Intuition: Cognitive Belief-Driven Reinforcement Learning](http://arxiv.org/abs/2410.01739v3)** | 2025-06-12 | <details><summary>Accep...</summary><p>Accepted by ICML 2025 Workshop on Models of Human Feedback for AI Alignment</p></details> |
| **[PosterCraft: Rethinking High-Quality Aesthetic Poster Generation in a Unified Framework](http://arxiv.org/abs/2506.10741v1)** | 2025-06-12 |  |

## Robotics
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop](http://arxiv.org/abs/2506.10968v1)** | 2025-06-12 | <details><summary>Proje...</summary><p>Project page: https://www.eyerobot.net/</p></details> |
| **[Passivity-Centric Safe Reinforcement Learning for Contact-Rich Robotic Tasks](http://arxiv.org/abs/2503.00287v2)** | 2025-06-12 | revision version |
| **[Modeling Trust Dynamics in Robot-Assisted Delivery: Impact of Trust Repair Strategies](http://arxiv.org/abs/2506.10884v1)** | 2025-06-12 |  |
| **[Data-Driven Prediction of Dynamic Interactions Between Robot Appendage and Granular Material](http://arxiv.org/abs/2506.10875v1)** | 2025-06-12 |  |
| **[Human-Robot Navigation using Event-based Cameras and Reinforcement Learning](http://arxiv.org/abs/2506.10790v1)** | 2025-06-12 | <details><summary>https...</summary><p>https://ibugueno.github.io/hr-navigation-using-event-cameras-and-rl/</p></details> |
| **[APEX: Action Priors Enable Efficient Exploration for Skill Imitation on Articulated Robots](http://arxiv.org/abs/2505.10022v2)** | 2025-06-12 |  |
| **[Robotic Policy Learning via Human-assisted Action Preference Optimization](http://arxiv.org/abs/2506.07127v2)** | 2025-06-12 |  |
| **[To what extent can current French mobile network support agricultural robots?](http://arxiv.org/abs/2505.10044v2)** | 2025-06-12 |  |
| **[Safety-Ensured Robotic Control Framework for Cutting Task Automation in Endoscopic Submucosal Dissection](http://arxiv.org/abs/2503.08214v2)** | 2025-06-12 | <details><summary>This ...</summary><p>This article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2025.3578607</p></details> |
| **[Help or Hindrance: Understanding the Impact of Robot Communication in Action Teams](http://arxiv.org/abs/2506.08892v2)** | 2025-06-12 | <details><summary>This ...</summary><p>This is the author's original submitted version of the paper accepted to the 2025 IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). \c{opyright} 2025 IEEE. Personal use of this material is permitted. For any other use, please contact IEEE</p></details> |
| **[Innovative Adaptive Imaged Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators](http://arxiv.org/abs/2506.10240v1)** | 2025-06-11 | <details><summary>22 pa...</summary><p>22 pages, 13 figures. To appear in: Innovative Adaptive Image-Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators, IntechOpen, 2024. For published version, see this http URL: https://doi.org/10.5772/intechopen.1004857</p></details> |
| **[Exploring EEG Responses during Observation of Actions Performed by Human Actor and Humanoid Robot](http://arxiv.org/abs/2506.10170v1)** | 2025-06-11 |  |
| **[Cybernetic Marionette: Channeling Collective Agency Through a Wearable Robot in a Live Dancer-Robot Duet](http://arxiv.org/abs/2506.10079v1)** | 2025-06-11 |  |
| **[From Theory to Practice: Advancing Multi-Robot Path Planning Algorithms and Applications](http://arxiv.org/abs/2506.09914v1)** | 2025-06-11 | Ph.D. thesis |
| **[Aucamp: An Underwater Camera-Based Multi-Robot Platform with Low-Cost, Distributed, and Robust Localization](http://arxiv.org/abs/2506.09876v1)** | 2025-06-11 |  |

