---
title: Latest 15 Papers - May 21, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Embodied AI
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds](http://arxiv.org/abs/2505.14366v1)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to: Intelligent Autonomous Systems (IAS) 2025 as Late Breaking Report</p></details> |
| **[Latent Action Learning Requires Supervision in the Presence of Distractors](http://arxiv.org/abs/2502.00379v4)** | 2025-05-20 | <details><summary>ICML ...</summary><p>ICML 2025, Poster, Source code: https://github.com/dunnolab/laom</p></details> |
| **[Toward Embodied AGI: A Review of Embodied AI and the Road Ahead](http://arxiv.org/abs/2505.14235v1)** | 2025-05-20 |  |
| **[Towards Omnidirectional Reasoning with 360-R1: A Dataset, Benchmark, and GRPO-based Method](http://arxiv.org/abs/2505.14197v1)** | 2025-05-20 |  |
| **[Unconventional Hexacopters via Evolution and Learning: Performance Gains and New Insights](http://arxiv.org/abs/2505.14129v1)** | 2025-05-20 | <details><summary>16 pa...</summary><p>16 pages, 14 figures, currently under review</p></details> |
| **[RefDrone: A Challenging Benchmark for Referring Expression Comprehension in Drone Scenes](http://arxiv.org/abs/2502.00392v2)** | 2025-05-19 |  |
| **[PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI](http://arxiv.org/abs/2505.12707v1)** | 2025-05-19 | 9 pages, 8 figures |
| **[EWMBench: Evaluating Scene, Motion, and Semantic Quality in Embodied World Models](http://arxiv.org/abs/2505.09694v2)** | 2025-05-18 | <details><summary>Websi...</summary><p>Website: https://github.com/AgibotTech/EWMBench</p></details> |
| **[Visuospatial Cognitive Assistant](http://arxiv.org/abs/2505.12312v1)** | 2025-05-18 | <details><summary>31 pa...</summary><p>31 pages, 10 figures, 6 tables. The implementation and fine-tuned model (ViCA-7B) are publicly available at https://huggingface.co/nkkbr/ViCA. The ViCA-322K dataset can be found at https://huggingface.co/datasets/nkkbr/ViCA-322K, and the ViCA-Thinking-2.68K dataset is at https://huggingface.co/datasets/nkkbr/ViCA-thinking-2.68k</p></details> |
| **[Emergent Active Perception and Dexterity of Simulated Humanoids from Visual Reinforcement Learning](http://arxiv.org/abs/2505.12278v1)** | 2025-05-18 | <details><summary>Proje...</summary><p>Project page: https://zhengyiluo.github.io/PDC</p></details> |
| **[Are Multimodal Large Language Models Ready for Omnidirectional Spatial Reasoning?](http://arxiv.org/abs/2505.11907v1)** | 2025-05-17 |  |
| **[Multi-Modal Multi-Task (M3T) Federated Foundation Models for Embodied AI: Potentials and Challenges for Edge Integration](http://arxiv.org/abs/2505.11191v1)** | 2025-05-16 | <details><summary>10 pa...</summary><p>10 pages, 3 figures, 3 tables</p></details> |
| **[Embodied AI in Machine Learning -- is it Really Embodied?](http://arxiv.org/abs/2505.10705v1)** | 2025-05-15 | 16 pages, 3 figures |
| **[KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems](http://arxiv.org/abs/2505.10183v1)** | 2025-05-15 | <details><summary>9 pag...</summary><p>9 pages, 4 figures. Jieke Lin and Wanyu Wang contributed equally to this work</p></details> |
| **[EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation](http://arxiv.org/abs/2505.10105v1)** | 2025-05-15 |  |

## Reinforcement Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning](http://arxiv.org/abs/2505.14684v1)** | 2025-05-20 |  |
| **[Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning](http://arxiv.org/abs/2505.14677v1)** | 2025-05-20 |  |
| **[Reward Reasoning Model](http://arxiv.org/abs/2505.14674v1)** | 2025-05-20 |  |
| **[General-Reasoner: Advancing LLM Reasoning Across All Domains](http://arxiv.org/abs/2505.14652v1)** | 2025-05-20 |  |
| **[Think Only When You Need with Large Hybrid-Reasoning Models](http://arxiv.org/abs/2505.14631v1)** | 2025-05-20 |  |
| **[TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning](http://arxiv.org/abs/2505.14625v1)** | 2025-05-20 |  |
| **[Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning](http://arxiv.org/abs/2505.14585v1)** | 2025-05-20 |  |
| **[Performance Optimization of Energy-Harvesting Underlay Cognitive Radio Networks Using Reinforcement Learning](http://arxiv.org/abs/2505.14581v1)** | 2025-05-20 |  |
| **[KIPPO: Koopman-Inspired Proximal Policy Optimization](http://arxiv.org/abs/2505.14566v1)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted for IJCAI 2025. This arXiv submission is the full version of the conference paper, including the appendix and supplementary material omitted from the IJCAI proceedings</p></details> |
| **[Bellman operator convergence enhancements in reinforcement learning algorithms](http://arxiv.org/abs/2505.14564v1)** | 2025-05-20 |  |
| **[KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation](http://arxiv.org/abs/2505.14552v1)** | 2025-05-20 | 22 pages |
| **[Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study](http://arxiv.org/abs/2505.14544v1)** | 2025-05-20 |  |
| **[Energy-Efficient Deep Reinforcement Learning with Spiking Transformers](http://arxiv.org/abs/2505.14533v1)** | 2025-05-20 |  |
| **[NavBench: A Unified Robotics Benchmark for Reinforcement Learning-Based Autonomous Navigation](http://arxiv.org/abs/2505.14526v1)** | 2025-05-20 | <details><summary>Submi...</summary><p>Submitted for publication. Under review (2025)</p></details> |
| **[Personalised Insulin Adjustment with Reinforcement Learning: An In-Silico Validation for People with Diabetes on Intensive Insulin Treatment](http://arxiv.org/abs/2505.14477v1)** | 2025-05-20 |  |

## Robotics
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models](http://arxiv.org/abs/2409.15250v3)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted at ICRA-2025, Atlanta</p></details> |
| **[NavBench: A Unified Robotics Benchmark for Reinforcement Learning-Based Autonomous Navigation](http://arxiv.org/abs/2505.14526v1)** | 2025-05-20 | <details><summary>Submi...</summary><p>Submitted for publication. Under review (2025)</p></details> |
| **[End-to-End and Highly-Efficient Differentiable Simulation for Robotics](http://arxiv.org/abs/2409.07107v2)** | 2025-05-20 |  |
| **[Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds](http://arxiv.org/abs/2505.14366v1)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to: Intelligent Autonomous Systems (IAS) 2025 as Late Breaking Report</p></details> |
| **[Sampling-Based System Identification with Active Exploration for Legged Robot Sim2Real Learning](http://arxiv.org/abs/2505.14266v1)** | 2025-05-20 |  |
| **[Safe Distributed Control of Multi-Robot Systems with Communication Delays](http://arxiv.org/abs/2402.09382v4)** | 2025-05-20 | <details><summary>Copyr...</summary><p>Copyright (c) 2025 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org</p></details> |
| **[GRoQ-Loco: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets](http://arxiv.org/abs/2505.10973v2)** | 2025-05-20 | <details><summary>18pag...</summary><p>18pages, 16figures, 6tables</p></details> |
| **[Task-oriented Robotic Manipulation with Vision Language Models](http://arxiv.org/abs/2410.15863v2)** | 2025-05-20 |  |
| **[AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory](http://arxiv.org/abs/2505.14030v1)** | 2025-05-20 |  |
| **[RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction](http://arxiv.org/abs/2505.12224v2)** | 2025-05-20 |  |
| **[Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning](http://arxiv.org/abs/2505.13925v1)** | 2025-05-20 |  |
| **[Robotic Monitoring of Colorimetric Leaf Sensors for Precision Agriculture](http://arxiv.org/abs/2505.13916v1)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to the Novel Approaches for Precision Agriculture and Forestry with Autonomous Robots IEEE ICRA Workshop - 2025</p></details> |
| **[Enhancing Robot Navigation Policies with Task-Specific Uncertainty Managements](http://arxiv.org/abs/2505.13837v1)** | 2025-05-20 |  |
| **[Toward Real-World Cooperative and Competitive Soccer with Quadrupedal Robot Teams](http://arxiv.org/abs/2505.13834v1)** | 2025-05-20 | 11 pages, 12 figures |
| **[RoCoDA: Counterfactual Data Augmentation for Data-Efficient Robot Learning from Demonstrations](http://arxiv.org/abs/2411.16959v2)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to 2025 IEEE International Conference on Robotics and Automation (ICRA)</p></details> |

