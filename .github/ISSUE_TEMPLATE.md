---
title: Latest 15 Papers - April 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Embodied AI
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HUMOTO: A 4D Dataset of Mocap Human Object Interactions](http://arxiv.org/abs/2504.10414v1)** | 2025-04-14 | 19 pages, 15 figures |
| **[Efficient Task-specific Conditional Diffusion Policies: Shortcut Model Acceleration and SO(3) Optimization](http://arxiv.org/abs/2504.09927v1)** | 2025-04-14 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025 Workshop on 2nd MEIS</p></details> |
| **[GeoNav: Empowering MLLMs with Explicit Geospatial Reasoning Abilities for Language-Goal Aerial Navigation](http://arxiv.org/abs/2504.09587v1)** | 2025-04-13 |  |
| **[FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents](http://arxiv.org/abs/2504.08581v1)** | 2025-04-11 |  |
| **[EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents](http://arxiv.org/abs/2501.11858v2)** | 2025-04-11 |  |
| **[MrSteve: Instruction-Following Agents in Minecraft with What-Where-When Memory](http://arxiv.org/abs/2411.06736v5)** | 2025-04-11 | <details><summary>Accep...</summary><p>Accepted to ICLR 2025</p></details> |
| **[STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](http://arxiv.org/abs/2503.23765v2)** | 2025-04-09 |  |
| **[Functionality understanding and segmentation in 3D scenes](http://arxiv.org/abs/2411.16310v4)** | 2025-04-08 | <details><summary>CVPR ...</summary><p>CVPR 2025 Highlight. Camera ready version. 20 pages, 12 figures, 7 tables</p></details> |
| **[SIGHT: Single-Image Conditioned Generation of Hand Trajectories for Hand-Object Interaction](http://arxiv.org/abs/2503.22869v2)** | 2025-04-05 |  |
| **[SeGuE: Semantic Guided Exploration for Mobile Robots](http://arxiv.org/abs/2504.03629v1)** | 2025-04-04 | <details><summary>6 pag...</summary><p>6 pages, 4 figures, 3 tables</p></details> |
| **[Decision SpikeFormer: Spike-Driven Transformer for Decision Making](http://arxiv.org/abs/2504.03800v1)** | 2025-04-04 | <details><summary>This ...</summary><p>This work has been accepted to CVPR 2025</p></details> |
| **[3D-Mem: 3D Scene Memory for Embodied Exploration and Reasoning](http://arxiv.org/abs/2411.17735v5)** | 2025-04-04 |  |
| **[MORAL: A Multimodal Reinforcement Learning Framework for Decision Making in Autonomous Laboratories](http://arxiv.org/abs/2504.03153v1)** | 2025-04-04 | <details><summary>9 pag...</summary><p>9 pages, 14 figures and 3 tables</p></details> |
| **[TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization](http://arxiv.org/abs/2503.19901v2)** | 2025-04-03 | CVPR 2025 |
| **[IDMR: Towards Instance-Driven Precise Visual Correspondence in Multimodal Retrieval](http://arxiv.org/abs/2504.00954v1)** | 2025-04-01 |  |

## Reinforcement Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Weight Ensembling Improves Reasoning in Language Models](http://arxiv.org/abs/2504.10478v1)** | 2025-04-14 |  |
| **[Co-optimizing Physical Reconfiguration Parameters and Controllers for an Origami-inspired Reconfigurable Manipulator](http://arxiv.org/abs/2504.10474v1)** | 2025-04-14 |  |
| **[GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents](http://arxiv.org/abs/2504.10458v1)** | 2025-04-14 |  |
| **[Heimdall: test-time scaling on the generative verification](http://arxiv.org/abs/2504.10337v1)** | 2025-04-14 |  |
| **[InstructEngine: Instruction-driven Text-to-Image Alignment](http://arxiv.org/abs/2504.10329v1)** | 2025-04-14 | 8 pages, 7 figures |
| **[Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning](http://arxiv.org/abs/2502.05996v2)** | 2025-04-14 |  |
| **[VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model](http://arxiv.org/abs/2504.07615v2)** | 2025-04-14 | <details><summary>11 pa...</summary><p>11 pages, fix some minor typos in the previous version</p></details> |
| **[Vision based driving agent for race car simulation environments](http://arxiv.org/abs/2504.10266v1)** | 2025-04-14 | <details><summary>Submi...</summary><p>Submitted to ICMCE 2024 (https://icmce.org/2024.html)</p></details> |
| **[Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for Dynamic Data Acquisition in Digital Twins](http://arxiv.org/abs/2504.10248v1)** | 2025-04-14 | 18 pages, 14 figures |
| **[Look Before You Leap: Enhancing Attention and Vigilance Regarding Harmful Content with GuidelineLLM](http://arxiv.org/abs/2412.10423v2)** | 2025-04-14 | AAAI 2025 |
| **[Deep Reasoning Translation via Reinforcement Learning](http://arxiv.org/abs/2504.10187v1)** | 2025-04-14 |  |
| **[MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning](http://arxiv.org/abs/2504.10160v1)** | 2025-04-14 | <details><summary>Work ...</summary><p>Work in progress. Our code is available at https://github.com/fzp0424/MT-R1-Zero</p></details> |
| **[A Human-Sensitive Controller: Adapting to Human Ergonomics and Physical Constraints via Reinforcement Learning](http://arxiv.org/abs/2504.10102v1)** | 2025-04-14 |  |
| **[DartControl: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control](http://arxiv.org/abs/2410.05260v3)** | 2025-04-14 | <details><summary>Updat...</summary><p>Updated ICLR camera ready version</p></details> |
| **[Pay Attention to What and Where? Interpretable Feature Extractor in Vision-based Deep Reinforcement Learning](http://arxiv.org/abs/2504.10071v1)** | 2025-04-14 |  |

## Robotics
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Intelligent Framework for Human-Robot Collaboration: Dynamic Ergonomics and Adaptive Decision-Making](http://arxiv.org/abs/2503.07901v2)** | 2025-04-14 | <details><summary>15 pa...</summary><p>15 pagine, 8figure, 3 tabelle, formato conferenza IEEE</p></details> |
| **[Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain](http://arxiv.org/abs/2504.10390v1)** | 2025-04-14 | <details><summary>8 pag...</summary><p>8 pages, 6 figures, 6 tables</p></details> |
| **[Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning](http://arxiv.org/abs/2502.05996v2)** | 2025-04-14 |  |
| **[Siamese Network with Dual Attention for EEG-Driven Social Learning: Bridging the Human-Robot Gap in Long-Tail Autonomous Driving](http://arxiv.org/abs/2504.10296v1)** | 2025-04-14 | 50 pages, 18 figures |
| **[Ankle Exoskeletons in Walking and Load-Carrying Tasks: Insights into Biomechanics and Human-Robot Interaction](http://arxiv.org/abs/2504.10294v1)** | 2025-04-14 |  |
| **[Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for Distance and Geometry Perception in Robotic Manipulation](http://arxiv.org/abs/2504.10280v1)** | 2025-04-14 |  |
| **[Shoulder Range of Motion Rehabilitation Robot Incorporating Scapulohumeral Rhythm for Frozen Shoulder](http://arxiv.org/abs/2504.10163v1)** | 2025-04-14 | <details><summary>This ...</summary><p>This is a preprint of a manuscript that has been submitted for publication</p></details> |
| **[MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation](http://arxiv.org/abs/2503.20384v2)** | 2025-04-14 |  |
| **[EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical Challenge in Multi-Robot Control](http://arxiv.org/abs/2504.10030v1)** | 2025-04-14 |  |
| **[Velocity-free task-space regulator for robot manipulators with external disturbances](http://arxiv.org/abs/2503.02634v2)** | 2025-04-14 |  |
| **[GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control](http://arxiv.org/abs/2504.09997v1)** | 2025-04-14 |  |
| **[Walk along: An Experiment on Controlling the Mobile Robot 'Spot' with Voice and Gestures](http://arxiv.org/abs/2407.11218v5)** | 2025-04-14 |  |
| **[Dynamic-Dark SLAM: RGB-Thermal Cooperative Robot Vision Strategy for Multi-Person Tracking in Both Well-Lit and Low-Light Scenes](http://arxiv.org/abs/2503.12768v2)** | 2025-04-14 | <details><summary>10 pa...</summary><p>10 pages, 9 figures, technical report</p></details> |
| **[Robust Output-Feedback MPC for Nonlinear Systems with Applications to Robotic Exploration](http://arxiv.org/abs/2504.09768v1)** | 2025-04-14 | <details><summary>Accep...</summary><p>Accepted for publication in L-CSS</p></details> |
| **[Adapting Robot's Explanation for Failures Based on Observed Human Behavior in Human-Robot Collaboration](http://arxiv.org/abs/2504.09717v1)** | 2025-04-13 | <details><summary>Under...</summary><p>Under review, Manuscript in submission for IROS 2025</p></details> |

