---
title: Latest 15 Papers - April 22, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Embodied AI
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](http://arxiv.org/abs/2503.23765v3)** | 2025-04-21 |  |
| **[GeoNav: Empowering MLLMs with Explicit Geospatial Reasoning Abilities for Language-Goal Aerial Navigation](http://arxiv.org/abs/2504.09587v2)** | 2025-04-21 |  |
| **[WMNav: Integrating Vision-Language Models into World Models for Object Goal Navigation](http://arxiv.org/abs/2503.02247v2)** | 2025-04-16 | 8 pages, 5 figures |
| **[3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians](http://arxiv.org/abs/2504.11218v2)** | 2025-04-16 | <details><summary>The f...</summary><p>The first large-scale 3D Gaussians Affordance Reasoning Benchmark</p></details> |
| **[Reasoning in visual navigation of end-to-end trained agents: a dynamical systems approach](http://arxiv.org/abs/2503.08306v4)** | 2025-04-15 |  |
| **[Concept Enhancement Engineering: A Lightweight and Efficient Robust Defense Against Jailbreak Attacks in Embodied AI](http://arxiv.org/abs/2504.13201v1)** | 2025-04-15 |  |
| **[HUMOTO: A 4D Dataset of Mocap Human Object Interactions](http://arxiv.org/abs/2504.10414v1)** | 2025-04-14 | 19 pages, 15 figures |
| **[Efficient Task-specific Conditional Diffusion Policies: Shortcut Model Acceleration and SO(3) Optimization](http://arxiv.org/abs/2504.09927v1)** | 2025-04-14 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025 Workshop on 2nd MEIS</p></details> |
| **[FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents](http://arxiv.org/abs/2504.08581v1)** | 2025-04-11 |  |
| **[EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents](http://arxiv.org/abs/2501.11858v2)** | 2025-04-11 |  |
| **[MrSteve: Instruction-Following Agents in Minecraft with What-Where-When Memory](http://arxiv.org/abs/2411.06736v5)** | 2025-04-11 | <details><summary>Accep...</summary><p>Accepted to ICLR 2025</p></details> |
| **[Functionality understanding and segmentation in 3D scenes](http://arxiv.org/abs/2411.16310v4)** | 2025-04-08 | <details><summary>CVPR ...</summary><p>CVPR 2025 Highlight. Camera ready version. 20 pages, 12 figures, 7 tables</p></details> |
| **[SIGHT: Single-Image Conditioned Generation of Hand Trajectories for Hand-Object Interaction](http://arxiv.org/abs/2503.22869v2)** | 2025-04-05 |  |
| **[SeGuE: Semantic Guided Exploration for Mobile Robots](http://arxiv.org/abs/2504.03629v1)** | 2025-04-04 | <details><summary>6 pag...</summary><p>6 pages, 4 figures, 3 tables</p></details> |
| **[Decision SpikeFormer: Spike-Driven Transformer for Decision Making](http://arxiv.org/abs/2504.03800v1)** | 2025-04-04 | <details><summary>This ...</summary><p>This work has been accepted to CVPR 2025</p></details> |

## Reinforcement Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[RILe: Reinforced Imitation Learning](http://arxiv.org/abs/2406.08472v4)** | 2025-04-21 |  |
| **[VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models](http://arxiv.org/abs/2504.15279v1)** | 2025-04-21 | <details><summary>Code,...</summary><p>Code, data, and baselines are available at https://visulogic-benchmark.github.io/VisuLogic</p></details> |
| **[Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning](http://arxiv.org/abs/2504.15275v1)** | 2025-04-21 |  |
| **[FlowReasoner: Reinforcing Query-Level Meta-Agents](http://arxiv.org/abs/2504.15257v1)** | 2025-04-21 |  |
| **[BlendRL: A Framework for Merging Symbolic and Neural Policy Learning](http://arxiv.org/abs/2410.11689v2)** | 2025-04-21 | <details><summary>ICLR ...</summary><p>ICLR 2025 (Spotlight)</p></details> |
| **[DRAGON: Distributional Rewards Optimize Diffusion Generative Models](http://arxiv.org/abs/2504.15217v1)** | 2025-04-21 |  |
| **[Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs](http://arxiv.org/abs/2504.15210v1)** | 2025-04-21 |  |
| **[Beyond Binary Opinions: A Deep Reinforcement Learning-Based Approach to Uncertainty-Aware Competitive Influence Maximization](http://arxiv.org/abs/2504.15131v1)** | 2025-04-21 |  |
| **[A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment](http://arxiv.org/abs/2504.15129v1)** | 2025-04-21 |  |
| **[Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN](http://arxiv.org/abs/2504.15099v1)** | 2025-04-21 |  |
| **[Think2SQL: Reinforce LLM Reasoning Capabilities for Text2SQL](http://arxiv.org/abs/2504.15077v1)** | 2025-04-21 | 15 pages |
| **[Energy-Efficient UAV-Mounted RIS for IoT: A Hybrid Energy Harvesting and DRL Approach](http://arxiv.org/abs/2504.15043v1)** | 2025-04-21 |  |
| **[Energy-Efficient Irregular RIS-aided UAV-Assisted Optimization: A Deep Reinforcement Learning Approach](http://arxiv.org/abs/2504.15031v1)** | 2025-04-21 |  |
| **[Accelerating Goal-Conditioned RL Algorithms and Research](http://arxiv.org/abs/2408.11052v3)** | 2025-04-21 | <details><summary>Websi...</summary><p>Website: https://michalbortkiewicz.github.io/JaxGCRL/ Code: https://github.com/MichalBortkiewicz/JaxGCRL</p></details> |
| **[SkyReels-V2: Infinite-length Film Generative Model](http://arxiv.org/abs/2504.13074v3)** | 2025-04-21 | 31 pages,10 figures |

## Robotics
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Cascade IPG Observer for Underwater Robot State Estimation](http://arxiv.org/abs/2504.15235v1)** | 2025-04-21 | <details><summary>ICRA ...</summary><p>ICRA 2025 (International Conference on Robotics and Automation), Atlanta, USA</p></details> |
| **[A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing](http://arxiv.org/abs/2504.15226v1)** | 2025-04-21 |  |
| **[SPARK-Remote: A Cost-Effective System for Remote Bimanual Robot Teleoperation](http://arxiv.org/abs/2504.05488v2)** | 2025-04-21 |  |
| **[Precision Robotic Spot-Spraying: Reducing Herbicide Use and Enhancing Environmental Outcomes in Sugarcane](http://arxiv.org/abs/2401.13931v2)** | 2025-04-21 | <details><summary>36 pa...</summary><p>36 pages, 17 figures, 4 tables. Published at the Computers and Electronics in Agriculture journal</p></details> |
| **[Tactile sensing enables vertical obstacle negotiation for elongate many-legged robots](http://arxiv.org/abs/2504.08615v2)** | 2025-04-21 | Accepted by RSS 2025 |
| **[A0: An Affordance-Aware Hierarchical Model for General Robotic Manipulation](http://arxiv.org/abs/2504.12636v2)** | 2025-04-21 |  |
| **[Safe Autonomous Environmental Contact for Soft Robots using Control Barrier Functions](http://arxiv.org/abs/2504.14755v1)** | 2025-04-20 | 10 pages, 10 figures |
| **[Latent Representations for Visual Proprioception in Inexpensive Robots](http://arxiv.org/abs/2504.14634v1)** | 2025-04-20 |  |
| **[RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for Robots](http://arxiv.org/abs/2504.14604v1)** | 2025-04-20 |  |
| **[K2MUSE: A human lower limb multimodal dataset under diverse conditions for facilitating rehabilitation robotics](http://arxiv.org/abs/2504.14602v1)** | 2025-04-20 | <details><summary>23 pa...</summary><p>23 pages, 13 figures,4 tables</p></details> |
| **[Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction](http://arxiv.org/abs/2504.14588v1)** | 2025-04-20 | Accepted by CVPR2025 |
| **[Going Down the Abstraction Stream with Augmented Reality and Tangible Robots: the Case of Vector Instruction](http://arxiv.org/abs/2504.14562v1)** | 2025-04-20 |  |
| **[ExFace: Expressive Facial Control for Humanoid Robots with Diffusion Transformers and Bootstrap Training](http://arxiv.org/abs/2504.14477v1)** | 2025-04-20 |  |
| **[Experience-based Refinement of Task Planning Knowledge in Autonomous Robots](http://arxiv.org/abs/2504.14259v1)** | 2025-04-19 |  |
| **[Collision Induced Binding and Transport of Shape Changing Robot Pairs](http://arxiv.org/abs/2504.14170v1)** | 2025-04-19 | <details><summary>7 pag...</summary><p>7 pages, 6 figures, submitted to PRL</p></details> |

